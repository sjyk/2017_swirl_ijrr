\section{Phase 1: Sequence Learning}
\seclabel{hirl}
The first phase of \hirl is to segment the demonstrations.

\subsection{Formalizing Segmentation}
While, there are a number of different algorithms for segmenting a set of demonstrations into sub-sequences, not all are directly applicable to the learning problem setting.
This is because the segments are used in two different ways. During the offline phases of the algorithm (Sequence Learning and Reward Learning), the algorithm observes the full demonstration trajectory.
These segments are used to generate the local reward functions.
Since it is offline, the segmentation is fully observed that is all of the learning components know which segment is active at any given time step.

During the online phase of the algorithm (Policy Learning), the algorithm only observes the partial trajectory up-to the current time-step.
From these observations, we need to be able to known which segment is currently active.
In this sense, segmentation introduces a problem of partial observation even if the original task is fully observed.
First, we need to formalize under what conditions this is possible and efficient.

Trivially, some algorithms are not causal since they might require knowledge of future data (e.g., a forward-backward HMM algorithm).
Even if the algorithm is causal, it might have an arbitrary dependence on the past leading to inefficient estimation of the currently active segment.
To address this problem, we formalize the following condition:

\begin{definition}[Markov Segmentation]
A Markov segmentation function is a task segmentation where the segmentation index of time $t+1$ can be completely determined by the state at time $t$ and the index at time $t$:
\[
i_{t+1} = \mathbf{M}(s_t, i_t)  
\]
\end{definition}

\subsection{General Framework}
We now describe a general framework that takes a general segmentation algorithm and extracts a Markov segmentation criteria.
Suppose, we are given a general function that just identifies candidate segment endpoints.
Such a function is weaker than a segmentation function since it does not globally label the detected segments.

\begin{definition}[Transition Indicator Function]
A transition indicator function $\mathbf{T}$ is a function that maps each kinematic state in a demonstration $d$ to $\{0,1\}$:
\[
\mathbf{T}: d \mapsto \{0,1\}
\]
\end{definition}

The above definition naturally leads to a notion of transition states, the states and times at which transitions occur.

\begin{definition}[Transition States]
For a demonstration set $D$, Transition States are the set of state-time tuples where the indicator is 1:
\[
\Gamma = \{(x,t) \in D : \mathbf{T}(t) = 1\}
\]
\end{definition}

We model the set $\Gamma$ as samples from an underlying distribution over the state-space and time.
\[
\Gamma \sim f(x,t)
\]
Then, we can model the distribution as a GMM:
\[
f(x,t) = GMM(\pi,\{\mu_1,...,\mu_k\}, \{\Sigma_1,...,\Sigma_k\})
\]
The interpretation of this distribution is $\pi$ describes the fraction of transitions assigned to each mixture component, $\mu_i$ describes the centroid of the mixture component, and $\Sigma$ describes the covariance.
Our prior work~\cite{krishnan2015tsc,murali2016}, describes a number of practical optimizations such as pruning low-confidence mixture components.

One can think of these mixture as defining ellipsoids by taking the confidence level-sets in the state-space and time that characterize regions where transitions occur.
These regions are ordered since they are also defined over time, since we make the assumption that the confidence threshold for the level sets is tuned so that the regions are disjoint.
Thus, reaching one of these regions defines a testable condition based on the current state, time, and previously reached regions--which is a Markov Segmentation Function.
The result is exactly the set of transition regions: $G = [\rho_1, \rho_2,...,\rho_k]$, and segmentation of each demonstration trajectory into $k$ segments.

In typical GMM formulations, one must specify the number of mixture components $k$ before hand.
However, we apply results from Bayesian non-parametric statistics and jointly solve for the component parameters and the number of components using a Dirichlet Process~\cite{kulis2011revisiting}.
Using a DP, the number of components grows with the complexity of the observed data (we denote this as DP-GMM).

\subsection{GMM-based Segmentation}
As an instance of the general framework, we use Gaussian Mixture Models to segment demonstrations in our experiments.
This technique is quite general and applies to a large class of linear and non-linear systems.

A popular approach for transition identification is to use Gaussian Mixture Models~\cite{calinon2014skills}, namely, cluster all state observations and identify times at which $x_t$ is in a different cluster than $x_{t+1}$.
For a given time $t$, we can define a window of length $\ell$ as:
\[
\mathbf{n}^{(\ell)}_t = [x_{t-\ell},...,x_{t}]^\intercal
\]
Then, for each demonstration trajectory we can also generate a trajectory of $T_i - \ell$ windowed states:
\[
\mathbf{d}^{(\ell)}_i = [\mathbf{n}^{(\ell)}_\ell,...,\mathbf{n}^{(\ell)}_{T_i}]
\]
Over the entire set of windowed demonstrations, we collect a dataset of all of the $\mathbf{n}^{(\ell)}_t$ vectors.
We fit GMM model to these vectors.
The GMM model defines $m$ multivariate Gaussian distributions and a probability that each observation $\mathbf{n}^{(\ell)}_t$ is sampled from each of the $m$ distributions.
We annotate each observation with the most likely mixture component.
Times such that $\mathbf{n}^{(\ell)}_t$ and $\mathbf{n}^{(\ell)}_{t+1}$ have different most likely components are marked as transitions.
This has the interpretation of fitting a locally linear regression to the data (refer to~\cite{moldovan2013dirichlet, khansari2011learning, kruger2010learning, krishnan2015tsc,murali2016} for details).

If the system's local dynamics are non-linear or discontinuous, we can smooth out the dynamics with a kernel embedding of the trajectories.
The basic idea is to apply Kernelized PCA to the features before learning the transitions--a technique used in Computer Vision~\cite{DBLP:conf/nips/MikaSSMSR98}.
By changing the kernel function (i.e., the similarity metric between states), we can essentially change the definition of local linearity.

Let $\mathbf{\kappa}(x_i,x_j)$ define a kernel function over the states.
For example, if $\mathbf{\kappa}$ is the radial basis function (RBF), then:
$ \mathbf{\kappa}(x_i,x_j) = e^{\frac{-\|x_i-x_j\|_2^2}{2\sigma}}$.
$\mathbf{\kappa}$ naturally defines a matrix $M$ where: $M_{ij} = \mathbf{\kappa}(x_i,x_j)$. 
The top $p'$ eigenvalues define a new embedded feature vector for each $\omega$ in $\mathbb{R}^{p'}$.
We can now apply the algorithm above in this embedded feature space.

\begin{phase}[t]
\small
\DontPrintSemicolon
\caption{Sequence Learning \label{alg:tsh1}}
\KwData{Demonstration $\mathcal{D}$}

Fit a DP-GMM model to $\mathcal{D}$ and identify the set of transitions $\Theta$, defined as all $(x_t,t)$  where  $(x_{t+1},t+1)$  has a different cluster.

Fit a DP-GMM to the states in $\Theta$.

Prune clusters that do not have one transition from all demonstrations.

The result of is $G = [\rho_1, \rho_2,...,\rho_m]$ where each $\rho$ is a disjoint ellipsoidal region of the state-space and time interval.

\KwResult{G}
\end{phase}
