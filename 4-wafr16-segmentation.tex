\section{\hirl: Sequence Learning}
\seclabel{hirl}
The first phase of \hirl is to segment the demonstrations into consistent segments.
Let $D=\{d_i\}$ be a set of demonstrations of a robotic task.
Each demonstration of a task $d$ is a discrete-time sequence of $T$ state vectors in a feature-space $\mathcal{X}$.
The feature space can be a concatenation of kinematic features $X_{k}$ (e.g., robot position) and sensory features $X_{s}$ (e.g., visual features from the environment).

\begin{definition}[Segmentation]
A segmentation of task is defined as a function $\mathbf{S}_k$ that assigns each state in every demonstration trajectory to an integer $1,2,...,k$:
\[
\mathbf{S}_k: d \mapsto [k]
\]
and $\mathcal{S}_k$ is a non-decreasing function in time (no repetitions).
\end{definition}

This means that not only is each demonstration divided into k segments but these segments are corresponded across demonstrations with indices.
This is the definition of sequential task segmentation used in our prior work~\cite{krishnan2015tsc,murali2016}.
However, in this paper, we need a further restriction that the segmentation method preserves the Markov Decision Process structure, and can be applied during a rollout.

\begin{definition}[Markov Segmentation]
A Markov segmentation function is a task segmentation where the segmentation index of time $t+1$ can be completely determined by the state at time $t$ and the index at time $t$:
\[
i_{t+1} = \mathbf{M}(s_t, i_t)  
\]
\end{definition}

Not all segmentation functions satisfy the Markov segmentation property. For example, a model where the terminal state of the trajectory determines how the trajectory is divided into segments.
This can happen in Bayesian algorithms that require a forward-backward estimate for segment inference.

\subsection{Learning Markov Segmentation Criteria}
The first challenge in \hirl is designing such Markov Segmentation functions.
Our key insight is that one can extract such a function with a probabilistic model from an underlying non-Markov segmentation technique.
Suppose, we are given a general function that just identifies candidate segment endpoints.
Such a function is weaker than a segmentation function since it does not globally label the detected segments.

\begin{definition}[Transition Indicator Function]
A transition indicator function $\mathbf{T}$ is a function that maps each kinematic state in a demonstration $d$ to $\{0,1\}$:
\[
\mathbf{T}: d \mapsto \{0,1\}
\]
\end{definition}

The above definition naturally leads to a notion of transition states, the states and times at which transitions occur.

\begin{definition}[Transition States]
For a demonstration set $D$, Transition States are the set of state-time tuples where the indicator is 1:
\[
\Gamma = \{(x,t) \in D : \mathbf{T}(t) = 1\}
\]
\end{definition}

We model the set $\Gamma$ as samples from an underlying distribution over the state-space and time.
\[
\Gamma \sim f(x,t)
\]
Then, we can model the distribution as a GMM:
\[
f(x,t) = GMM(\pi,\{\mu_1,...,\mu_k\}, \{\Sigma_1,...,\Sigma_k\})
\]
The interpretation of this distribution is $\pi$ describes the fraction of transitions assigned to each mixture component, $\mu_i$ describes the centroid of the mixture component, and $\Sigma$ describes the covariance.
Our prior work~\cite{krishnan2015tsc,murali2016}, describes a number of practical optimizations such as pruning low-confidence mixture components.

One can think of these mixture as defining ellipsoids by taking the confidence level-sets in the state-space and time that characterize regions where transitions occur.
These regions are ordered since they are also defined over time, since we make the assumption that the confidence threshold for the level sets is tuned so that the regions are disjoint.
Thus, reaching one of these regions defines a testable condition based on the current state, time, and previously reached regions--which is a Markov Segmentation Function.
The result is exactly the set of transition regions: $G = [\rho_1, \rho_2,...,\rho_k]$, and segmentation of each demonstration trajectory into $k$ segments.

\subsection{Experimental Implementation}
In our experiments, we use the following transition identification algorithm.
A popular approach for transition identification is to use Gaussian Mixture Models~\cite{calinon2014skills}, namely, cluster all state observations and identify times at which $x_t$ is in a different cluster than $x_{t+1}$.
For a given time $t$, we can define a window of length $\ell$ as:
\[
\mathbf{n}^{(\ell)}_t = [x_{t-\ell},...,x_{t}]^\intercal
\]
Then, for each demonstration trajectory we can also generate a trajectory of $T_i - \ell$ windowed states:
\[
\mathbf{d}^{(\ell)}_i = [\mathbf{n}^{(\ell)}_\ell,...,\mathbf{n}^{(\ell)}_{T_i}]
\]
Over the entire set of windowed demonstrations, we collect a dataset of all of the $\mathbf{n}^{(\ell)}_t$ vectors.
We fit GMM model to these vectors.
The GMM model defines $m$ multivariate Gaussian distributions and a probability that each observation $\mathbf{n}^{(\ell)}_t$ is sampled from each of the $m$ distributions.
We annotate each observation with the most likely mixture component.
Times such that $\mathbf{n}^{(\ell)}_t$ and $\mathbf{n}^{(\ell)}_{t+1}$ have different most likely components are marked as transitions.
This has the interpretation of fitting a locally linear regression to the data (refer to~\cite{moldovan2013dirichlet, khansari2011learning, kruger2010learning, krishnan2015tsc,murali2016} for details).
In typical GMM formulations, one must specify the number of mixture components $k$ before hand.
However, we apply results from Bayesian non-parametric statistics and jointly solve for the component parameters and the number of components using a Dirichlet Process~\cite{kulis2011revisiting}.
Using a DP, the number of components grows with the complexity of the observed data (we denote this as DP-GMM).


\subsection{Relaxing Local Linearity}
GMM's are a type of local Bayesian linear regression, but we can easily relax the linearity assumption.
We relax the linear dynamics assumption with a kernel embedding of the trajectories.
The basic idea is to apply Kernelized PCA to the features before learning the transitions--a technique used in Computer Vision~\cite{DBLP:conf/nips/MikaSSMSR98}.
By changing the kernel function (i.e., the similarity metric between states), we can essentially change the definition of local linearity.

Let $\mathbf{\kappa}(x_i,x_j)$ define a kernel function over the states.
For example, if $\mathbf{\kappa}$ is the radial basis function (RBF), then:
$ \mathbf{\kappa}(x_i,x_j) = e^{\frac{-\|x_i-x_j\|_2^2}{2\sigma}}$.
$\mathbf{\kappa}$ naturally defines a matrix $M$ where: $M_{ij} = \mathbf{\kappa}(x_i,x_j)$. 
The top $p'$ eigenvalues define a new embedded feature vector for each $\omega$ in $\mathbb{R}^{p'}$.
We can now apply the algorithm above in this embedded feature space.

\begin{phase}[t]
\small
\DontPrintSemicolon
\caption{Sequence Learning \label{alg:tsh1}}
\KwData{Demonstration $\mathcal{D}$}

Fit a DP-GMM model to $\mathcal{D}$ and identify the set of transitions $\Theta$, defined as all $(x_t,t)$  where  $(x_{t+1},t+1)$  has a different cluster.

Fit a DP-GMM to the states in $\Theta$.

Prune clusters that do not have one transition from all demonstrations.

The result of is $G = [\rho_1, \rho_2,...,\rho_m]$ where each $\rho$ is a disjoint ellipsoidal region of the state-space and time interval.

\KwResult{G}
\end{phase}
